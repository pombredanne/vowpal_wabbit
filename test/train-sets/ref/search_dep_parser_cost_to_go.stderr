Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/wsj_small.dparser.vw.gz.cache
Reading datafile = train-sets/wsj_small.dparser.vw.gz
num sources = 1
average    since      instance            current true      current predicted   cur   cur   predic    cache  examples          
loss       last        counter           output prefix          output prefix  pass   pol     made     hits    gener  beta    
88.000000  88.000000         1  [43:1 5:2 5:2 5:2 1..] [0:8 1:1 2:1 3:1 4:..]     0     0      144        0      144  0.000000
47.500000  7.000000          2  [2:2 3:5 0:8 3:7 3:4 ] [2:2 0:8 2:4 2:4 2:4 ]     0     0      156        0      156  0.001439
37.250000  27.000000         4  [4:2 4:2 4:2 7:5 6:..] [2:2 7:5 2:4 2:4 2:..]     0     0      246        0      246  0.002128
28.500000  19.750000         8  [4:2 4:2 4:2 5:5 0:..] [3:2 3:2 4:2 5:5 0:..]     1     0      543        0      543  0.004848
15.375000  2.250000         16  [43:1 5:2 5:2 5:2 1..] [43:1 5:2 5:2 5:2 1..]     3     0     1134        0     1134  0.009851

finished run
number of examples per pass = 5
passes used = 6
weighted example sum = 30
weighted label sum = 0
average loss = 8.2
total feature number = 579491
